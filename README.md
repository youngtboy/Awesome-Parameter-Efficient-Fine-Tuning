# Awesome-Parameter-Efficient-Fine-Tuning
A paper list of parameter-efficient fine-tuning method

## Survey
- Visual Tuning | **[arxiv'23]** |[`[paper]`](https://arxiv.org/abs/2305.06061)

# All Papers

## 2019
- **[Adapter]** Parameter-Efficient Transfer Learning for NLP | **[ICML'19]** | [`[paper]`](https://arxiv.org/abs/1902.00751) [`[code]`](https://github.com/google-research/adapter-bert)

## 2021
- **[LoRA]** LoRA: Low-Rank Adaptation of Large Language Models | **[ICLR'22]** | [`[paper]`](https://arxiv.org/abs/2106.09685) [`[code]`](https://github.com/microsoft/LoRA)

- **[BitFit/Bias]** BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models | **[ACL'22]** | [`[paper]`](https://arxiv.org/abs/2106.10199) [`[code]`](https://github.com/benzakenelad/BitFit)

- **[CoOp]** Learning to Prompt for Vision-Language Models | **[IJCV'22]** | [`[paper]`](https://arxiv.org/abs/2109.01134) [`[code]`](https://github.com/KaiyangZhou/CoOp)

## 2022
- **[VPT]** Visual Prompt Tuning | **[ECCV'22]** | [`[paper]`](https://arxiv.org/abs/2203.12119) [`[code]`](https://github.com/kmnp/vpt) 

- **[CoCoOp]** Conditional Prompt Learning for Vision-Language Models | **[CVPR'22]** | [`[paper]`](https://arxiv.org/abs/2203.05557) [`[code]`](https://github.com/KaiyangZhou/CoOp) 

- **[AdaptFormer]** AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition | **[NIPS'22]** | [`[paper]`](https://arxiv.org/abs/2205.13535) [`[code]`](https://github.com/ShoufaChen/AdaptFormer) 

- **[NOAH]** Neural Prompt Search | **[arxiv'22]** | [`[paper]`](https://arxiv.org/abs/2206.04673) [`[code]`](https://github.com/ZhangYuanhan-AI/NOAH)

- **[SSF]** Scaling & Shifting Your Features: A New Baseline for Efficient Model Tuning | **[NIPS'22]** | [`[paper]`](https://arxiv.org/abs/2210.08823) [`[code]`](https://github.com/dongzelian/SSF)

- **[FacT]** FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer | **[AAAI23]** | [`[paper]`](https://arxiv.org/abs/2212.03145)

## 2023
- **[RepAdapter]** Towards Efficient Visual Adaption via Structural Re-parameterization | **[arxiv'23]** | [`[paper]`](https://arxiv.org/abs/2302.08106) [`[code]`](https://github.com/luogen1996/RepAdapter)

- **[AdaLoRA]** AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning | **[ICLR'23]** | [`[paper]`](https://arxiv.org/abs/2303.10512) [`[code]`](https://github.com/QingruZhang/AdaLoRA)

- **[SVDiff]** SVDiff: Compact Parameter Space for Diffusion Fine-Tuning  | **[ICCV'23]** | [`[paper]`](https://arxiv.org/abs/2303.11305) [`[code]`](https://github.com/mkshing/svdiff-pytorch)

- **[GatedPromptTuning]** Improving Visual Prompt Tuning for Self-supervised Vision Transformers | **[ICML'23]** | [`[paper]`](https://arxiv.org/abs/2306.05067) [`[code]`](https://github.com/ryongithub/GatedPromptTuning)

- **[PVP]** PVP: Pre-trained Visual Parameter-Efficient Tuning | **[arxiv'23]** | [`[paper]`](https://arxiv.org/abs/2304.13639)

- **[E<sup>2</sup>VPT]** E<sup>2</sup>VPT: An Effective and Efficient Approach for Visual Prompt Tuning | **[ICCV'23]** | [`[paper]`](https://arxiv.org/abs/2307.13770) [`[code]`](https://github.com/ChengHan111/E2VPT)
  
- **[DVPT]** Dynamic Visual Prompt Tuning for Parameter Efficient Transfer Learning | **[PRCV'23]** | [`[paper]`](https://arxiv.org/abs/2309.06123) 

- **[ARC]** Efficient Adaptation of Large Vision Transformer via Adapter Re-Composing | **[NIPS'23]** | [`[paper]`](https://arxiv.org/abs/2310.06234) [`[code]`](https://github.com/DavidYanAnDe/ARC)
  
## 2024
- **[FLoRA]** Flora: Low-Rank Adapters Are Secretly Gradient Compressors | **[ICML'24]** | [`[paper]`](https://arxiv.org/abs/2402.03293) [`[code]`](https://github.com/BorealisAI/flora-opt)

- **[DoRA]** DoRA: Weight-Decomposed Low-Rank Adaptation | **[ICML'24]** | [`[paper]`](https://arxiv.org/abs/2402.09353) [`[code]`](https://github.com/NVlabs/DoRA)

- **[LoRA+]** LoRA+: Efficient Low Rank Adaptation of Large Models  | **[ICML'24]** | [`[paper]`](https://arxiv.org/abs/2402.12354)

- **[PiSSA]** PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models | **[NIPS'24]** | [`[paper]`](https://arxiv.org/abs/2404.02948) [`[code]`](https://github.com/GraphPKU/PiSSA)

- **[TriLoRA]** TriLoRA: Integrating SVD for Advanced Style Personalization in Text-to-Image Generation  | **[arxiv'24]** | [`[paper]`](https://arxiv.org/abs/2405.11236)

- **[Spectral Adapter]** Spectral Adapter: Fine-Tuning in Spectral Space | **[NIPS'24]** | [`[paper]`](https://arxiv.org/abs/2405.13952) [`[code]`](https://github.com/pilancilab/spectral_adapter)

- **[FLoRA]** FLoRA: Low-Rank Core Space for N-dimension | **[arxiv'24]** | [`[paper]`](https://arxiv.org/abs/2405.14739) [`[code]`](https://github.com/SJTU-DeepVisionLab/FLoRA)

- **[MiLoRA]** MiLoRA: Harnessing Minor Singular Components for Parameter-Efficient LLM Finetuning | **[arxiv'24]** | [`[paper]`](https://arxiv.org/abs/2406.09044)

- **[MoSLoRA]** Mixture-of-Subspaces in Low-Rank Adaptation | **[arxiv'24]** | [`[paper]`](https://arxiv.org/abs/2406.11909) [`[code]`](https://github.com/wutaiqiang/MoSLoRA)

- **[LoRA-GA]** LoRA-GA: Low-Rank Adaptation with Gradient Approximation | **[NIPS'24]** | [`[paper]`](https://arxiv.org/abs/2407.05000) [`[code]`](https://github.com/Outsider565/LoRA-GA)

- **[LoRA-Pro]** LoRA-Pro: Are Low-Rank Adapters Properly Optimized? | **[arxiv'24]** | [`[paper]`](https://arxiv.org/abs/2407.18242) [`[code]`](https://github.com/mrflogs/LoRA-Pro)

- **[LoRA-Dash]** Unleashing the Power of Task-Specific Directions in Parameter Efficient Fine-tuning | **[arxiv'24]** | [`[paper]`](https://arxiv.org/abs/2409.01035) 

